38183.3s 1 
38183.3s 2 Epoch  iou_loss  dfl_loss  cls_loss
38233.9s 3 0%|          | 0/63 [00:00<?, ?it/s]                                             297/299    0.4875    0.5233     1.084:   0%|          | 0/63 [00:00<?, ?it/s]   297/299    0.4875    0.5233     1.084:   2%|▏         | 1/63 [00:00<00:49,  1   297/299    0.5053    0.5472     1.124:   2%|▏         | 1/63 [00:01<00:49,  1   297/299    0.5053    0.5472     1.124:   3%|▎         | 2/63 [00:01<00:48,  1   297/299     0.493     0.548     1.141:   3%|▎         | 2/63 [00:02<00:48,  1   297/299     0.493     0.548     1.141:   5%|▍         | 3/63 [00:02<00:48,  1   297/299    0.4985    0.5501      1.14:   5%|▍         | 3/63 [00:03<00:48,  1   297/299    0.4985    0.5501      1.14:   6%|▋         | 4/63 [00:03<00:47,  1   297/299    0.4976    0.5496     1.127:   6%|▋         | 4/63 [00:03<00:47,  1   297/299    0.4976    0.5496     1.127:   8%|▊         | 5/63 [00:03<00:46,  1   297/299    0.5025    0.5476     1.133:   8%|▊         | 5/63 [00:04<00:46,  1   297/299    0.5025    0.5476     1.133:  10%|▉         | 6/63 [00:04<00:45,  1   297/299    0.4956    0.5486     1.151:  10%|▉         | 6/63 [00:05<00:45,  1   297/299    0.4956    0.5486     1.151:  11%|█         | 7/63 [00:05<00:44,  1   297/299    0.5055    0.5571     1.171:  11%|█         | 7/63 [00:06<00:44,  1   297/299    0.5055    0.5571     1.171:  13%|█▎        | 8/63 [00:06<00:43,  1   297/299    0.5105    0.5542     1.163:  13%|█▎        | 8/63 [00:07<00:43,  1   297/299    0.5105    0.5542     1.163:  14%|█▍        | 9/63 [00:07<00:42,  1   297/299    0.5071    0.5585     1.168:  14%|█▍        | 9/63 [00:07<00:42,  1   297/299    0.5071    0.5585     1.168:  16%|█▌        | 10/63 [00:07<00:41,     297/299    0.5107    0.5572      1.17:  16%|█▌        | 10/63 [00:08<00:41,     297/299    0.5107    0.5572      1.17:  17%|█▋        | 11/63 [00:08<00:42,     297/299    0.5161    0.5639      1.17:  17%|█▋        | 11/63 [00:09<00:42,     297/299    0.5161    0.5639      1.17:  19%|█▉        | 12/63 [00:09<00:40,     297/299    0.5095     0.564      1.17:  19%|█▉        | 12/63 [00:10<00:40,     297/299    0.5095     0.564      1.17:  21%|██        | 13/63 [00:10<00:39,     297/299    0.5112      0.56     1.164:  21%|██        | 13/63 [00:11<00:39,     297/299    0.5112      0.56     1.164:  22%|██▏       | 14/63 [00:11<00:38,     297/299    0.5139    0.5585     1.165:  22%|██▏       | 14/63 [00:11<00:38,     297/299    0.5139    0.5585     1.165:  24%|██▍       | 15/63 [00:11<00:38,     297/299    0.5157    0.5623     1.168:  24%|██▍       | 15/63 [00:12<00:38,     297/299    0.5157    0.5623     1.168:  25%|██▌       | 16/63 [00:12<00:38,     297/299    0.5199     0.565     1.169:  25%|██▌       | 16/63 [00:13<00:38,     297/299    0.5199     0.565     1.169:  27%|██▋       | 17/63 [00:13<00:37,     297/299    0.5187     0.564     1.166:  27%|██▋       | 17/63 [00:14<00:37,     297/299    0.5187     0.564     1.166:  29%|██▊       | 18/63 [00:14<00:36,     297/299    0.5175    0.5639     1.167:  29%|██▊       | 18/63 [00:15<00:36,     297/299    0.5175    0.5639     1.167:  30%|███       | 19/63 [00:15<00:35,     297/299     0.511    0.5609     1.169:  30%|███       | 19/63 [00:16<00:35,     297/299     0.511    0.5609     1.169:  32%|███▏      | 20/63 [00:16<00:34,     297/299    0.5137    0.5615     1.175:  32%|███▏      | 20/63 [00:16<00:34,     297/299    0.5137    0.5615     1.175:  33%|███▎      | 21/63 [00:16<00:33,     297/299    0.5094    0.5604     1.177:  33%|███▎      | 21/63 [00:17<00:33,     297/299    0.5094    0.5604     1.177:  35%|███▍      | 22/63 [00:17<00:32,     297/299    0.5066    0.5589      1.17:  35%|███▍      | 22/63 [00:18<00:32,     297/299    0.5066    0.5589      1.17:  37%|███▋      | 23/63 [00:18<00:32,     297/299    0.5112    0.5629     1.171:  37%|███▋      | 23/63 [00:19<00:32,     297/299    0.5112    0.5629     1.171:  38%|███▊      | 24/63 [00:19<00:31,     297/299    0.5132    0.5639      1.17:  38%|███▊      | 24/63 [00:20<00:31,     297/299    0.5132    0.5639      1.17:  40%|███▉      | 25/63 [00:20<00:30,     297/299    0.5116    0.5607     1.168:  40%|███▉      | 25/63 [00:20<00:30,     297/299    0.5116    0.5607     1.168:  41%|████▏     | 26/63 [00:20<00:29,     297/299    0.5142    0.5615      1.17:  41%|████▏     | 26/63 [00:21<00:29,     297/299    0.5142    0.5615      1.17:  43%|████▎     | 27/63 [00:21<00:29,     297/299    0.5152    0.5612      1.17:  43%|████▎     | 27/63 [00:22<00:29,     297/299    0.5152    0.5612      1.17:  44%|████▍     | 28/63 [00:22<00:27,     297/299    0.5145    0.5611     1.175:  44%|████▍     | 28/63 [00:23<00:27,     297/299    0.5145    0.5611     1.175:  46%|████▌     | 29/63 [00:23<00:26,     297/299    0.5147    0.5612     1.174:  46%|████▌     | 29/63 [00:23<00:26,     297/299    0.5147    0.5612     1.174:  48%|████▊     | 30/63 [00:23<00:26,     297/299    0.5188    0.5611     1.176:  48%|████▊     | 30/63 [00:24<00:26,     297/299    0.5188    0.5611     1.176:  49%|████▉     | 31/63 [00:24<00:26,     297/299    0.5176    0.5594     1.174:  49%|████▉     | 31/63 [00:25<00:26,     297/299    0.5176    0.5594     1.174:  51%|█████     | 32/63 [00:25<00:24,     297/299     0.516    0.5584     1.175:  51%|█████     | 32/63 [00:26<00:24,     297/299     0.516    0.5584     1.175:  52%|█████▏    | 33/63 [00:26<00:24,     297/299    0.5155    0.5582     1.174:  52%|█████▏    | 33/63 [00:27<00:24,     297/299    0.5155    0.5582     1.174:  54%|█████▍    | 34/63 [00:27<00:23,     297/299    0.5149    0.5597     1.175:  54%|█████▍    | 34/63 [00:28<00:23,     297/299    0.5149    0.5597     1.175:  56%|█████▌    | 35/63 [00:28<00:23,     297/299    0.5159    0.5597     1.174:  56%|█████▌    | 35/63 [00:28<00:23,     297/299    0.5159    0.5597     1.174:  57%|█████▋    | 36/63 [00:28<00:22,     297/299    0.5145    0.5591     1.177:  57%|█████▋    | 36/63 [00:29<00:22,     297/299    0.5145    0.5591     1.177:  59%|█████▊    | 37/63 [00:29<00:21,     297/299    0.5141    0.5589     1.178:  59%|█████▊    | 37/63 [00:30<00:21,     297/299    0.5141    0.5589     1.178:  60%|██████    | 38/63 [00:30<00:20,     297/299    0.5161    0.5605      1.18:  60%|██████    | 38/63 [00:31<00:20,     297/299    0.5161    0.5605      1.18:  62%|██████▏   | 39/63 [00:31<00:19,     297/299    0.5165    0.5604      1.18:  62%|██████▏   | 39/63 [00:32<00:19,     297/299    0.5165    0.5604      1.18:  63%|██████▎   | 40/63 [00:32<00:18,     297/299    0.5161    0.5605      1.18:  63%|██████▎   | 40/63 [00:32<00:18,     297/299    0.5161    0.5605      1.18:  65%|██████▌   | 41/63 [00:32<00:17,     297/299     0.515    0.5599     1.179:  65%|██████▌   | 41/63 [00:33<00:17,     297/299     0.515    0.5599     1.179:  67%|██████▋   | 42/63 [00:33<00:16,     297/299    0.5158    0.5611      1.18:  67%|██████▋   | 42/63 [00:34<00:16,     297/299    0.5158    0.5611      1.18:  68%|██████▊   | 43/63 [00:34<00:16,     297/299    0.5171    0.5607      1.18:  68%|██████▊   | 43/63 [00:35<00:16,     297/299    0.5171    0.5607      1.18:  70%|██████▉   | 44/63 [00:35<00:15,     297/299    0.5165    0.5602     1.179:  70%|██████▉   | 44/63 [00:36<00:15,     297/299    0.5165    0.5602     1.179:  71%|███████▏  | 45/63 [00:36<00:14,     297/299    0.5156    0.5604      1.18:  71%|███████▏  | 45/63 [00:36<00:14,     297/299    0.5156    0.5604      1.18:  73%|███████▎  | 46/63 [00:36<00:13,     297/299    0.5159    0.5609     1.181:  73%|███████▎  | 46/63 [00:37<00:13,     297/299    0.5159    0.5609     1.181:  75%|███████▍  | 47/63 [00:37<00:12,     297/299    0.5153      0.56      1.18:  75%|███████▍  | 47/63 [00:38<00:12,     297/299    0.5153      0.56      1.18:  76%|███████▌  | 48/63 [00:38<00:12,     297/299    0.5158    0.5606     1.179:  76%|███████▌  | 48/63 [00:39<00:12,     297/299    0.5158    0.5606     1.179:  78%|███████▊  | 49/63 [00:39<00:11,     297/299    0.5163    0.5616      1.18:  78%|███████▊  | 49/63 [00:40<00:11,     297/299    0.5163    0.5616      1.18:  79%|███████▉  | 50/63 [00:40<00:10,     297/299    0.5155    0.5623      1.18:  79%|███████▉  | 50/63 [00:40<00:10,     297/299    0.5155    0.5623      1.18:  81%|████████  | 51/63 [00:40<00:09,     297/299    0.5148    0.5621     1.181:  81%|████████  | 51/63 [00:41<00:09,     297/299    0.5148    0.5621     1.181:  83%|████████▎ | 52/63 [00:41<00:08,     297/299    0.5141    0.5623     1.181:  83%|████████▎ | 52/63 [00:42<00:08,     297/299    0.5141    0.5623     1.181:  84%|████████▍ | 53/63 [00:42<00:07,     297/299     0.513    0.5613     1.179:  84%|████████▍ | 53/63 [00:43<00:07,     297/299     0.513    0.5613     1.179:  86%|████████▌ | 54/63 [00:43<00:07,     297/299    0.5139    0.5614     1.176:  86%|████████▌ | 54/63 [00:44<00:07,     297/299    0.5139    0.5614     1.176:  87%|████████▋ | 55/63 [00:44<00:06,     297/299     0.512    0.5612     1.176:  87%|████████▋ | 55/63 [00:44<00:06,     297/299     0.512    0.5612     1.176:  89%|████████▉ | 56/63 [00:44<00:05,     297/299    0.5124    0.5612     1.174:  89%|████████▉ | 56/63 [00:46<00:05,     297/299    0.5124    0.5612     1.174:  90%|█████████ | 57/63 [00:46<00:05,     297/299    0.5108    0.5609     1.172:  90%|█████████ | 57/63 [00:46<00:05,     297/299    0.5108    0.5609     1.172:  92%|█████████▏| 58/63 [00:46<00:04,     297/299    0.5098    0.5606     1.172:  92%|█████████▏| 58/63 [00:47<00:04,     297/299    0.5098    0.5606     1.172:  94%|█████████▎| 59/63 [00:47<00:03,     297/299    0.5092    0.5606     1.171:  94%|█████████▎| 59/63 [00:48<00:03,     297/299    0.5092    0.5606     1.171:  95%|█████████▌| 60/63 [00:48<00:02,     297/299    0.5099    0.5615     1.171:  95%|█████████▌| 60/63 [00:49<00:02,     297/299    0.5099    0.5615     1.171:  97%|█████████▋| 61/63 [00:49<00:01,     297/299    0.5109    0.5618     1.172:  97%|█████████▋| 61/63 [00:50<00:01,     297/299    0.5109    0.5618     1.172:  98%|█████████▊| 62/63 [00:50<00:00,     297/299    0.5107    0.5616     1.171:  98%|█████████▊| 62/63 [00:50<00:00,     297/299    0.5107    0.5616     1.171: 100%|██████████| 63/63 [00:50<00:00,     297/299    0.5107    0.5616     1.171: 100%|██████████| 63/63 [00:50<00:00,
38504.0s 4 Inferencing model in train datasets.:   0%|             | 0/157 [00:00<?, ?it/s]Inferencing model in train datasets.:   1%|     | 1/157 [00:01<03:06,  1.20s/it]Inferencing model in train datasets.:   1%|     | 2/157 [00:02<03:04,  1.19s/it]Inferencing model in train datasets.:   2%|     | 3/157 [00:03<03:32,  1.38s/it]Inferencing model in train datasets.:   3%|▏    | 4/157 [00:05<04:05,  1.60s/it]Inferencing model in train datasets.:   3%|▏    | 5/157 [00:07<03:52,  1.53s/it]Inferencing model in train datasets.:   4%|▏    | 6/157 [00:08<03:41,  1.46s/it]Inferencing model in train datasets.:   4%|▏    | 7/157 [00:10<03:47,  1.52s/it]Inferencing model in train datasets.:   5%|▎    | 8/157 [00:12<04:13,  1.70s/it]Inferencing model in train datasets.:   6%|▎    | 9/157 [00:14<04:08,  1.68s/it]Inferencing model in train datasets.:   6%|▎   | 10/157 [00:15<03:46,  1.54s/it]Inferencing model in train datasets.:   7%|▎   | 11/157 [00:17<04:04,  1.68s/it]Inferencing model in train datasets.:   8%|▎   | 12/157 [00:18<03:51,  1.60s/it]Inferencing model in train datasets.:   8%|▎   | 13/157 [00:20<03:44,  1.56s/it]Inferencing model in train datasets.:   9%|▎   | 14/157 [00:21<03:44,  1.57s/it]Inferencing model in train datasets.:  10%|▍   | 15/157 [00:23<03:42,  1.57s/it]Inferencing model in train datasets.:  10%|▍   | 16/157 [00:24<03:40,  1.57s/it]Inferencing model in train datasets.:  11%|▍   | 17/157 [00:26<03:34,  1.53s/it]Inferencing model in train datasets.:  11%|▍   | 18/157 [00:28<04:14,  1.83s/it]Inferencing model in train datasets.:  12%|▍   | 19/157 [00:30<04:18,  1.87s/it]Inferencing model in train datasets.:  13%|▌   | 20/157 [00:32<04:06,  1.80s/it]Inferencing model in train datasets.:  13%|▌   | 21/157 [00:34<03:55,  1.74s/it]Inferencing model in train datasets.:  14%|▌   | 22/157 [00:35<03:44,  1.66s/it]Inferencing model in train datasets.:  15%|▌   | 23/157 [00:36<03:29,  1.56s/it]Inferencing model in train datasets.:  15%|▌   | 24/157 [00:38<03:20,  1.51s/it]Inferencing model in train datasets.:  16%|▋   | 25/157 [00:40<03:33,  1.62s/it]Inferencing model in train datasets.:  17%|▋   | 26/157 [00:41<03:34,  1.64s/it]Inferencing model in train datasets.:  17%|▋   | 27/157 [00:43<03:22,  1.55s/it]Inferencing model in train datasets.:  18%|▋   | 28/157 [00:45<03:41,  1.72s/it]Inferencing model in train datasets.:  18%|▋   | 29/157 [00:47<03:44,  1.75s/it]Inferencing model in train datasets.:  19%|▊   | 30/157 [00:48<03:24,  1.61s/it]Inferencing model in train datasets.:  20%|▊   | 31/157 [00:50<03:27,  1.65s/it]Inferencing model in train datasets.:  20%|▊   | 32/157 [00:51<03:13,  1.55s/it]Inferencing model in train datasets.:  21%|▊   | 33/157 [00:52<02:59,  1.45s/it]Inferencing model in train datasets.:  22%|▊   | 34/157 [00:54<02:57,  1.44s/it]Inferencing model in train datasets.:  22%|▉   | 35/157 [00:55<02:59,  1.48s/it]Inferencing model in train datasets.:  23%|▉   | 36/157 [00:56<02:56,  1.45s/it]Inferencing model in train datasets.:  24%|▉   | 37/157 [00:58<02:53,  1.45s/it]Inferencing model in train datasets.:  24%|▉   | 38/157 [00:59<02:50,  1.43s/it]Inferencing model in train datasets.:  25%|▉   | 39/157 [01:02<03:35,  1.83s/it]Inferencing model in train datasets.:  25%|█   | 40/157 [01:03<03:15,  1.67s/it]Inferencing model in train datasets.:  26%|█   | 41/157 [01:05<03:07,  1.61s/it]Inferencing model in train datasets.:  27%|█   | 42/157 [01:06<03:03,  1.59s/it]Inferencing model in train datasets.:  27%|█   | 43/157 [01:08<02:51,  1.51s/it]Inferencing model in train datasets.:  28%|█   | 44/157 [01:09<02:46,  1.48s/it]Inferencing model in train datasets.:  29%|█▏  | 45/157 [01:10<02:39,  1.42s/it]Inferencing model in train datasets.:  29%|█▏  | 46/157 [01:12<02:43,  1.48s/it]Inferencing model in train datasets.:  30%|█▏  | 47/157 [01:14<02:54,  1.58s/it]Inferencing model in train datasets.:  31%|█▏  | 48/157 [01:15<02:43,  1.50s/it]Inferencing model in train datasets.:  31%|█▏  | 49/157 [01:17<02:46,  1.54s/it]Inferencing model in train datasets.:  32%|█▎  | 50/157 [01:19<03:06,  1.74s/it]Inferencing model in train datasets.:  32%|█▎  | 51/157 [01:21<03:02,  1.72s/it]Inferencing model in train datasets.:  33%|█▎  | 52/157 [01:23<03:05,  1.76s/it]Inferencing model in train datasets.:  34%|█▎  | 53/157 [01:25<03:11,  1.84s/it]Inferencing model in train datasets.:  34%|█▍  | 54/157 [01:26<02:52,  1.68s/it]Inferencing model in train datasets.:  35%|█▍  | 55/157 [01:27<02:43,  1.60s/it]Inferencing model in train datasets.:  36%|█▍  | 56/157 [01:29<02:44,  1.63s/it]Inferencing model in train datasets.:  36%|█▍  | 57/157 [01:31<02:54,  1.74s/it]Inferencing model in train datasets.:  37%|█▍  | 58/157 [01:34<03:30,  2.12s/it]Inferencing model in train datasets.:  38%|█▌  | 59/157 [01:36<03:11,  1.95s/it]Inferencing model in train datasets.:  38%|█▌  | 60/157 [01:37<02:51,  1.77s/it]Inferencing model in train datasets.:  39%|█▌  | 61/157 [01:39<02:50,  1.78s/it]Inferencing model in train datasets.:  39%|█▌  | 62/157 [01:40<02:46,  1.75s/it]Inferencing model in train datasets.:  40%|█▌  | 63/157 [01:42<02:42,  1.73s/it]Inferencing model in train datasets.:  41%|█▋  | 64/157 [01:43<02:29,  1.61s/it]Inferencing model in train datasets.:  41%|█▋  | 65/157 [01:45<02:38,  1.72s/it]Inferencing model in train datasets.:  42%|█▋  | 66/157 [01:47<02:41,  1.77s/it]Inferencing model in train datasets.:  43%|█▋  | 67/157 [01:49<02:38,  1.76s/it]Inferencing model in train datasets.:  43%|█▋  | 68/157 [01:50<02:29,  1.68s/it]Inferencing model in train datasets.:  44%|█▊  | 69/157 [01:52<02:34,  1.75s/it]Inferencing model in train datasets.:  45%|█▊  | 70/157 [01:54<02:40,  1.85s/it]Inferencing model in train datasets.:  45%|█▊  | 71/157 [01:56<02:32,  1.77s/it]Inferencing model in train datasets.:  46%|█▊  | 72/157 [01:58<02:37,  1.85s/it]Inferencing model in train datasets.:  46%|█▊  | 73/157 [01:59<02:20,  1.67s/it]Inferencing model in train datasets.:  47%|█▉  | 74/157 [02:01<02:29,  1.80s/it]Inferencing model in train datasets.:  48%|█▉  | 75/157 [02:04<02:39,  1.94s/it]Inferencing model in train datasets.:  48%|█▉  | 76/157 [02:06<02:39,  1.97s/it]Inferencing model in train datasets.:  49%|█▉  | 77/157 [02:08<02:43,  2.05s/it]Inferencing model in train datasets.:  50%|█▉  | 78/157 [02:10<02:34,  1.95s/it]Inferencing model in train datasets.:  50%|██  | 79/157 [02:11<02:22,  1.82s/it]Inferencing model in train datasets.:  51%|██  | 80/157 [02:13<02:21,  1.84s/it]Inferencing model in train datasets.:  52%|██  | 81/157 [02:15<02:23,  1.89s/it]Inferencing model in train datasets.:  52%|██  | 82/157 [02:17<02:16,  1.82s/it]Inferencing model in train datasets.:  53%|██  | 83/157 [02:19<02:19,  1.88s/it]Inferencing model in train datasets.:  54%|██▏ | 84/157 [02:21<02:16,  1.87s/it]Inferencing model in train datasets.:  54%|██▏ | 85/157 [02:23<02:18,  1.92s/it]Inferencing model in train datasets.:  55%|██▏ | 86/157 [02:24<02:14,  1.89s/it]Inferencing model in train datasets.:  55%|██▏ | 87/157 [02:26<02:10,  1.87s/it]Inferencing model in train datasets.:  56%|██▏ | 88/157 [02:28<02:14,  1.95s/it]Inferencing model in train datasets.:  57%|██▎ | 89/157 [02:30<02:14,  1.97s/it]Inferencing model in train datasets.:  57%|██▎ | 90/157 [02:32<02:07,  1.90s/it]Inferencing model in train datasets.:  58%|██▎ | 91/157 [02:34<02:03,  1.87s/it]Inferencing model in train datasets.:  59%|██▎ | 92/157 [02:36<01:54,  1.76s/it]Inferencing model in train datasets.:  59%|██▎ | 93/157 [02:38<02:01,  1.89s/it]Inferencing model in train datasets.:  60%|██▍ | 94/157 [02:40<02:09,  2.05s/it]Inferencing model in train datasets.:  61%|██▍ | 95/157 [02:42<02:02,  1.98s/it]Inferencing model in train datasets.:  61%|██▍ | 96/157 [02:44<02:04,  2.04s/it]Inferencing model in train datasets.:  62%|██▍ | 97/157 [02:46<01:56,  1.95s/it]Inferencing model in train datasets.:  62%|██▍ | 98/157 [02:48<01:49,  1.86s/it]Inferencing model in train datasets.:  63%|██▌ | 99/157 [02:49<01:44,  1.81s/it]Inferencing model in train datasets.:  64%|█▉ | 100/157 [02:51<01:43,  1.82s/it]Inferencing model in train datasets.:  64%|█▉ | 101/157 [02:53<01:43,  1.85s/it]Inferencing model in train datasets.:  65%|█▉ | 102/157 [02:55<01:42,  1.86s/it]Inferencing model in train datasets.:  66%|█▉ | 103/157 [02:57<01:40,  1.87s/it]Inferencing model in train datasets.:  66%|█▉ | 104/157 [02:59<01:39,  1.88s/it]Inferencing model in train datasets.:  67%|██ | 105/157 [03:01<01:47,  2.07s/it]Inferencing model in train datasets.:  68%|██ | 106/157 [03:03<01:45,  2.08s/it]Inferencing model in train datasets.:  68%|██ | 107/157 [03:05<01:34,  1.88s/it]Inferencing model in train datasets.:  69%|██ | 108/157 [03:06<01:28,  1.80s/it]Inferencing model in train datasets.:  69%|██ | 109/157 [03:08<01:29,  1.86s/it]Inferencing model in train datasets.:  70%|██ | 110/157 [03:10<01:27,  1.85s/it]Inferencing model in train datasets.:  71%|██ | 111/157 [03:13<01:39,  2.15s/it]Inferencing model in train datasets.:  71%|██▏| 112/157 [03:15<01:34,  2.10s/it]Inferencing model in train datasets.:  72%|██▏| 113/157 [03:17<01:28,  2.02s/it]Inferencing model in train datasets.:  73%|██▏| 114/157 [03:19<01:22,  1.93s/it]Inferencing model in train datasets.:  73%|██▏| 115/157 [03:20<01:18,  1.86s/it]Inferencing model in train datasets.:  74%|██▏| 116/157 [03:22<01:18,  1.91s/it]Inferencing model in train datasets.:  75%|██▏| 117/157 [03:25<01:24,  2.11s/it]Inferencing model in train datasets.:  75%|██▎| 118/157 [03:27<01:20,  2.07s/it]Inferencing model in train datasets.:  76%|██▎| 119/157 [03:29<01:16,  2.00s/it]Inferencing model in train datasets.:  76%|██▎| 120/157 [03:30<01:12,  1.95s/it]Inferencing model in train datasets.:  77%|██▎| 121/157 [03:32<01:05,  1.81s/it]Inferencing model in train datasets.:  78%|██▎| 122/157 [03:33<00:59,  1.69s/it]Inferencing model in train datasets.:  78%|██▎| 123/157 [03:36<01:10,  2.07s/it]Inferencing model in train datasets.:  79%|██▎| 124/157 [03:38<01:06,  2.02s/it]Inferencing model in train datasets.:  80%|██▍| 125/157 [03:41<01:07,  2.10s/it]Inferencing model in train datasets.:  80%|██▍| 126/157 [03:42<01:00,  1.94s/it]Inferencing model in train datasets.:  81%|██▍| 127/157 [03:44<00:55,  1.84s/it]Inferencing model in train datasets.:  82%|██▍| 128/157 [03:46<00:59,  2.05s/it]Inferencing model in train datasets.:  82%|██▍| 129/157 [03:48<00:53,  1.90s/it]Inferencing model in train datasets.:  83%|██▍| 130/157 [03:49<00:48,  1.80s/it]Inferencing model in train datasets.:  83%|██▌| 131/157 [03:51<00:43,  1.66s/it]Inferencing model in train datasets.:  84%|██▌| 132/157 [03:52<00:39,  1.58s/it]Inferencing model in train datasets.:  85%|██▌| 133/157 [03:54<00:38,  1.60s/it]Inferencing model in train datasets.:  85%|██▌| 134/157 [03:55<00:36,  1.60s/it]Inferencing model in train datasets.:  86%|██▌| 135/157 [03:57<00:37,  1.70s/it]Inferencing model in train datasets.:  87%|██▌| 136/157 [03:59<00:34,  1.63s/it]Inferencing model in train datasets.:  87%|██▌| 137/157 [04:01<00:34,  1.71s/it]Inferencing model in train datasets.:  88%|██▋| 138/157 [04:02<00:32,  1.68s/it]Inferencing model in train datasets.:  89%|██▋| 139/157 [04:04<00:28,  1.60s/it]Inferencing model in train datasets.:  89%|██▋| 140/157 [04:05<00:25,  1.49s/it]Inferencing model in train datasets.:  90%|██▋| 141/157 [04:06<00:22,  1.41s/it]Inferencing model in train datasets.:  90%|██▋| 142/157 [04:08<00:22,  1.47s/it]Inferencing model in train datasets.:  91%|██▋| 143/157 [04:10<00:23,  1.67s/it]Inferencing model in train datasets.:  92%|██▊| 144/157 [04:12<00:23,  1.81s/it]Inferencing model in train datasets.:  92%|██▊| 145/157 [04:14<00:21,  1.77s/it]Inferencing model in train datasets.:  93%|██▊| 146/157 [04:15<00:19,  1.73s/it]Inferencing model in train datasets.:  94%|██▊| 147/157 [04:17<00:16,  1.65s/it]Inferencing model in train datasets.:  94%|██▊| 148/157 [04:19<00:16,  1.80s/it]Inferencing model in train datasets.:  95%|██▊| 149/157 [04:20<00:13,  1.65s/it]Inferencing model in train datasets.:  96%|██▊| 150/157 [04:21<00:10,  1.53s/it]Inferencing model in train datasets.:  96%|██▉| 151/157 [04:23<00:08,  1.44s/it]Inferencing model in train datasets.:  97%|██▉| 152/157 [04:24<00:07,  1.49s/it]Inferencing model in train datasets.:  97%|██▉| 153/157 [04:25<00:05,  1.37s/it]Inferencing model in train datasets.:  98%|██▉| 154/157 [04:27<00:03,  1.31s/it]Inferencing model in train datasets.:  99%|██▉| 155/157 [04:28<00:02,  1.31s/it]Inferencing model in train datasets.:  99%|██▉| 156/157 [04:29<00:01,  1.28s/it]Inferencing model in train datasets.: 100%|███| 157/157 [04:30<00:00,  1.04s/it]Inferencing model in train datasets.: 100%|███| 157/157 [04:30<00:00,  1.72s/it]
38504.0s 5 
38504.0s 6 Evaluating speed.
38504.0s 7 
38504.0s 8 Evaluating mAP by pycocotools.
38504.0s 9 Saving runs/train/exp/predictions.json...
38670.3s 10 Epoch: 297 | mAP@0.5: 0.08538102036036377 | mAP@0.50:0.95: 0.04807447757500807
38670.3s 11 
38670.3s 12 Epoch  iou_loss  dfl_loss  cls_loss
38670.3s 13 0%|          | 0/63 [00:00<?, ?it/s]                                          loading annotations into memory...
38670.3s 14 Done (t=0.96s)
38670.3s 15 creating index...
38670.3s 16 index created!
38670.3s 17 Loading and preparing results...
38670.3s 18 DONE (t=9.78s)
38670.3s 19 creating index...
38670.3s 20 index created!
38670.3s 21 Running per image evaluation...
38670.3s 22 Evaluate annotation type *bbox*
38670.3s 23 DONE (t=93.22s).
38670.3s 24 Accumulating evaluation results...
38670.3s 25 DONE (t=34.37s).
38670.3s 26 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.048
38670.3s 27 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.085
38670.3s 28 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.048
38670.3s 29 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.022
38670.3s 30 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.050
38670.3s 31 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.069
38670.3s 32 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.117
38670.3s 33 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.236
38670.3s 34 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.260
38670.3s 35 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.104
38670.3s 36 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.277
38670.3s 37 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.374
38719.9s 38 298/299     0.482    0.5009       1.1:   0%|          | 0/63 [00:00<?, ?it/s]   298/299     0.482    0.5009       1.1:   2%|▏         | 1/63 [00:00<00:53,  1   298/299    0.5082    0.5376     1.115:   2%|▏         | 1/63 [00:01<00:53,  1   298/299    0.5082    0.5376     1.115:   3%|▎         | 2/63 [00:01<00:50,  1   298/299    0.4888    0.5288     1.101:   3%|▎         | 2/63 [00:02<00:50,  1   298/299    0.4888    0.5288     1.101:   5%|▍         | 3/63 [00:02<00:48,  1   298/299    0.4743     0.522     1.107:   5%|▍         | 3/63 [00:03<00:48,  1   298/299    0.4743     0.522     1.107:   6%|▋         | 4/63 [00:03<00:48,  1   298/299    0.4937    0.5361     1.132:   6%|▋         | 4/63 [00:04<00:48,  1   298/299    0.4937    0.5361     1.132:   8%|▊         | 5/63 [00:04<00:46,  1   298/299     0.487    0.5288     1.122:   8%|▊         | 5/63 [00:04<00:46,  1   298/299     0.487    0.5288     1.122:  10%|▉         | 6/63 [00:04<00:45,  1   298/299    0.4883    0.5386     1.133:  10%|▉         | 6/63 [00:05<00:45,  1   298/299    0.4883    0.5386     1.133:  11%|█         | 7/63 [00:05<00:44,  1   298/299     0.503    0.5471     1.154:  11%|█         | 7/63 [00:06<00:44,  1   298/299     0.503    0.5471     1.154:  13%|█▎        | 8/63 [00:06<00:44,  1   298/299    0.5078     0.549      1.15:  13%|█▎        | 8/63 [00:07<00:44,  1   298/299    0.5078     0.549      1.15:  14%|█▍        | 9/63 [00:07<00:42,  1   298/299    0.5039    0.5482     1.151:  14%|█▍        | 9/63 [00:08<00:42,  1   298/299    0.5039    0.5482     1.151:  16%|█▌        | 10/63 [00:08<00:42,     298/299    0.4993    0.5454     1.149:  16%|█▌        | 10/63 [00:08<00:42,     298/299    0.4993    0.5454     1.149:  17%|█▋        | 11/63 [00:08<00:41,     298/299    0.4996    0.5433     1.156:  17%|█▋        | 11/63 [00:09<00:41,     298/299    0.4996    0.5433     1.156:  19%|█▉        | 12/63 [00:09<00:42,     298/299    0.5019    0.5474     1.158:  19%|█▉        | 12/63 [00:10<00:42,     298/299    0.5019    0.5474     1.158:  21%|██        | 13/63 [00:10<00:40,     298/299    0.5006    0.5467     1.159:  21%|██        | 13/63 [00:11<00:40,     298/299    0.5006    0.5467     1.159:  22%|██▏       | 14/63 [00:11<00:39,     298/299    0.4966    0.5471     1.157:  22%|██▏       | 14/63 [00:12<00:39,     298/299    0.4966    0.5471     1.157:  24%|██▍       | 15/63 [00:12<00:38,     298/299    0.4995    0.5462     1.154:  24%|██▍       | 15/63 [00:12<00:38,     298/299    0.4995    0.5462     1.154:  25%|██▌       | 16/63 [00:12<00:38,     298/299    0.5006    0.5482     1.157:  25%|██▌       | 16/63 [00:13<00:38,     298/299    0.5006    0.5482     1.157:  27%|██▋       | 17/63 [00:13<00:36,     298/299    0.4981    0.5476     1.158:  27%|██▋       | 17/63 [00:14<00:36,     298/299    0.4981    0.5476     1.158:  29%|██▊       | 18/63 [00:14<00:35,     298/299    0.4981    0.5478      1.16:  29%|██▊       | 18/63 [00:15<00:35,     298/299    0.4981    0.5478      1.16:  30%|███       | 19/63 [00:15<00:34,     298/299    0.4963    0.5476     1.162:  30%|███       | 19/63 [00:16<00:34,     298/299    0.4963    0.5476     1.162:  32%|███▏      | 20/63 [00:16<00:34,     298/299    0.4962    0.5484     1.164:  32%|███▏      | 20/63 [00:16<00:34,     298/299    0.4962    0.5484     1.164:  33%|███▎      | 21/63 [00:16<00:33,     298/299    0.4957    0.5481     1.166:  33%|███▎      | 21/63 [00:17<00:33,     298/299    0.4957    0.5481     1.166:  35%|███▍      | 22/63 [00:17<00:32,     298/299    0.4938    0.5472     1.166:  35%|███▍      | 22/63 [00:18<00:32,     298/299    0.4938    0.5472     1.166:  37%|███▋      | 23/63 [00:18<00:31,     298/299    0.4942    0.5465     1.164:  37%|███▋      | 23/63 [00:19<00:31,     298/299    0.4942    0.5465     1.164:  38%|███▊      | 24/63 [00:19<00:31,     298/299    0.4954    0.5458      1.16:  38%|███▊      | 24/63 [00:20<00:31,     298/299    0.4954    0.5458      1.16:  40%|███▉      | 25/63 [00:20<00:30,     298/299    0.4982     0.548     1.161:  40%|███▉      | 25/63 [00:20<00:30,     298/299    0.4982     0.548     1.161:  41%|████▏     | 26/63 [00:20<00:29,     298/299    0.4992    0.5506      1.16:  41%|████▏     | 26/63 [00:21<00:29,     298/299    0.4992    0.5506      1.16:  43%|████▎     | 27/63 [00:21<00:28,     298/299    0.4976      0.55     1.156:  43%|████▎     | 27/63 [00:22<00:28,     298/299    0.4976      0.55     1.156:  44%|████▍     | 28/63 [00:22<00:30,     298/299    0.4998    0.5523     1.161:  44%|████▍     | 28/63 [00:23<00:30,     298/299    0.4998    0.5523     1.161:  46%|████▌     | 29/63 [00:23<00:29,     298/299    0.5016    0.5525     1.162:  46%|████▌     | 29/63 [00:24<00:29,     298/299    0.5016    0.5525     1.162:  48%|████▊     | 30/63 [00:24<00:28,     298/299    0.5018    0.5515     1.161:  48%|████▊     | 30/63 [00:25<00:28,     298/299    0.5018    0.5515     1.161:  49%|████▉     | 31/63 [00:25<00:27,     298/299    0.5031    0.5524     1.161:  49%|████▉     | 31/63 [00:26<00:27,     298/299    0.5031    0.5524     1.161:  51%|█████     | 32/63 [00:26<00:26,     298/299    0.5041    0.5527     1.161:  51%|█████     | 32/63 [00:26<00:26,     298/299    0.5041    0.5527     1.161:  52%|█████▏    | 33/63 [00:26<00:24,     298/299    0.5047    0.5524     1.158:  52%|█████▏    | 33/63 [00:27<00:24,     298/299    0.5047    0.5524     1.158:  54%|█████▍    | 34/63 [00:27<00:23,     298/299    0.5071    0.5549     1.161:  54%|█████▍    | 34/63 [00:28<00:23,     298/299    0.5071    0.5549     1.161:  56%|█████▌    | 35/63 [00:28<00:22,     298/299    0.5069    0.5557     1.162:  56%|█████▌    | 35/63 [00:29<00:22,     298/299    0.5069    0.5557     1.162:  57%|█████▋    | 36/63 [00:29<00:21,     298/299    0.5072    0.5574     1.165:  57%|█████▋    | 36/63 [00:30<00:21,     298/299    0.5072    0.5574     1.165:  59%|█████▊    | 37/63 [00:30<00:20,     298/299    0.5065    0.5564     1.162:  59%|█████▊    | 37/63 [00:30<00:20,     298/299    0.5065    0.5564     1.162:  60%|██████    | 38/63 [00:30<00:19,     298/299    0.5058    0.5558      1.16:  60%|██████    | 38/63 [00:31<00:19,     298/299    0.5058    0.5558      1.16:  62%|██████▏   | 39/63 [00:31<00:18,     298/299    0.5062    0.5561      1.16:  62%|██████▏   | 39/63 [00:32<00:18,     298/299    0.5062    0.5561      1.16:  63%|██████▎   | 40/63 [00:32<00:19,     298/299    0.5066    0.5549     1.159:  63%|██████▎   | 40/63 [00:33<00:19,     298/299    0.5066    0.5549     1.159:  65%|██████▌   | 41/63 [00:33<00:18,     298/299    0.5055    0.5546      1.16:  65%|██████▌   | 41/63 [00:34<00:18,     298/299    0.5055    0.5546      1.16:  67%|██████▋   | 42/63 [00:34<00:17,     298/299    0.5057    0.5551     1.159:  67%|██████▋   | 42/63 [00:34<00:17,     298/299    0.5057    0.5551     1.159:  68%|██████▊   | 43/63 [00:34<00:16,     298/299    0.5061    0.5553      1.16:  68%|██████▊   | 43/63 [00:35<00:16,     298/299    0.5061    0.5553      1.16:  70%|██████▉   | 44/63 [00:35<00:15,     298/299     0.508    0.5565     1.162:  70%|██████▉   | 44/63 [00:36<00:15,     298/299     0.508    0.5565     1.162:  71%|███████▏  | 45/63 [00:36<00:14,     298/299    0.5076    0.5568     1.163:  71%|███████▏  | 45/63 [00:37<00:14,     298/299    0.5076    0.5568     1.163:  73%|███████▎  | 46/63 [00:37<00:13,     298/299    0.5076    0.5563     1.163:  73%|███████▎  | 46/63 [00:38<00:13,     298/299    0.5076    0.5563     1.163:  75%|███████▍  | 47/63 [00:38<00:12,     298/299    0.5062    0.5561     1.164:  75%|███████▍  | 47/63 [00:39<00:12,     298/299    0.5062    0.5561     1.164:  76%|███████▌  | 48/63 [00:39<00:12,     298/299    0.5075    0.5575     1.165:  76%|███████▌  | 48/63 [00:39<00:12,     298/299    0.5075    0.5575     1.165:  78%|███████▊  | 49/63 [00:39<00:11,     298/299    0.5065    0.5569     1.167:  78%|███████▊  | 49/63 [00:40<00:11,     298/299    0.5065    0.5569     1.167:  79%|███████▉  | 50/63 [00:40<00:10,     298/299    0.5081    0.5562     1.167:  79%|███████▉  | 50/63 [00:41<00:10,     298/299    0.5081    0.5562     1.167:  81%|████████  | 51/63 [00:41<00:09,     298/299    0.5081    0.5555     1.167:  81%|████████  | 51/63 [00:42<00:09,     298/299    0.5081    0.5555     1.167:  83%|████████▎ | 52/63 [00:42<00:08,     298/299    0.5087    0.5563     1.166:  83%|████████▎ | 52/63 [00:43<00:08,     298/299    0.5087    0.5563     1.166:  84%|████████▍ | 53/63 [00:43<00:08,     298/299    0.5086    0.5562     1.166:  84%|████████▍ | 53/63 [00:43<00:08,     298/299    0.5086    0.5562     1.166:  86%|████████▌ | 54/63 [00:43<00:07,     298/299    0.5098    0.5556     1.168:  86%|████████▌ | 54/63 [00:44<00:07,     298/299    0.5098    0.5556     1.168:  87%|████████▋ | 55/63 [00:44<00:06,     298/299    0.5084    0.5556     1.169:  87%|████████▋ | 55/63 [00:45<00:06,     298/299    0.5084    0.5556     1.169:  89%|████████▉ | 56/63 [00:45<00:05,     298/299    0.5078    0.5561     1.171:  89%|████████▉ | 56/63 [00:46<00:05,     298/299    0.5078    0.5561     1.171:  90%|█████████ | 57/63 [00:46<00:04,     298/299    0.5069    0.5568     1.171:  90%|█████████ | 57/63 [00:46<00:04,     298/299    0.5069    0.5568     1.171:  92%|█████████▏| 58/63 [00:46<00:03,     298/299    0.5067    0.5572      1.17:  92%|█████████▏| 58/63 [00:47<00:03,     298/299    0.5067    0.5572      1.17:  94%|█████████▎| 59/63 [00:47<00:03,     298/299     0.506    0.5564     1.168:  94%|█████████▎| 59/63 [00:48<00:03,     298/299     0.506    0.5564     1.168:  95%|█████████▌| 60/63 [00:48<00:02,     298/299    0.5057    0.5566     1.167:  95%|█████████▌| 60/63 [00:49<00:02,     298/299    0.5057    0.5566     1.167:  97%|█████████▋| 61/63 [00:49<00:01,     298/299    0.5061    0.5569     1.169:  97%|█████████▋| 61/63 [00:50<00:01,     298/299    0.5061    0.5569     1.169:  98%|█████████▊| 62/63 [00:50<00:00,     298/299     0.506     0.556     1.171:  98%|█████████▊| 62/63 [00:50<00:00,     298/299     0.506     0.556     1.171: 100%|██████████| 63/63 [00:50<00:00,     298/299     0.506     0.556     1.171: 100%|██████████| 63/63 [00:50<00:00,
38721.8s 39 
38721.8s 40 Epoch  iou_loss  dfl_loss  cls_loss
38774.5s 41 0%|          | 0/63 [00:00<?, ?it/s]                                             299/299    0.5374    0.5873     1.202:   0%|          | 0/63 [00:00<?, ?it/s]   299/299    0.5374    0.5873     1.202:   2%|▏         | 1/63 [00:00<00:53,  1   299/299    0.5296       0.6     1.201:   2%|▏         | 1/63 [00:01<00:53,  1   299/299    0.5296       0.6     1.201:   3%|▎         | 2/63 [00:01<00:49,  1   299/299    0.5108    0.5863     1.205:   3%|▎         | 2/63 [00:02<00:49,  1   299/299    0.5108    0.5863     1.205:   5%|▍         | 3/63 [00:02<00:48,  1   299/299    0.5135     0.573     1.202:   5%|▍         | 3/63 [00:03<00:48,  1   299/299    0.5135     0.573     1.202:   6%|▋         | 4/63 [00:03<00:47,  1   299/299    0.5299    0.5717     1.206:   6%|▋         | 4/63 [00:04<00:47,  1   299/299    0.5299    0.5717     1.206:   8%|▊         | 5/63 [00:04<00:47,  1   299/299    0.5288    0.5709     1.213:   8%|▊         | 5/63 [00:04<00:47,  1   299/299    0.5288    0.5709     1.213:  10%|▉         | 6/63 [00:04<00:47,  1   299/299    0.5326    0.5682     1.199:  10%|▉         | 6/63 [00:05<00:47,  1   299/299    0.5326    0.5682     1.199:  11%|█         | 7/63 [00:05<00:48,  1   299/299    0.5364    0.5683     1.202:  11%|█         | 7/63 [00:06<00:48,  1   299/299    0.5364    0.5683     1.202:  13%|█▎        | 8/63 [00:06<00:46,  1   299/299    0.5225     0.566     1.202:  13%|█▎        | 8/63 [00:07<00:46,  1   299/299    0.5225     0.566     1.202:  14%|█▍        | 9/63 [00:07<00:45,  1   299/299    0.5248     0.568     1.199:  14%|█▍        | 9/63 [00:08<00:45,  1   299/299    0.5248     0.568     1.199:  16%|█▌        | 10/63 [00:08<00:43,     299/299    0.5236    0.5696     1.191:  16%|█▌        | 10/63 [00:09<00:43,     299/299    0.5236    0.5696     1.191:  17%|█▋        | 11/63 [00:09<00:42,     299/299    0.5217    0.5691      1.19:  17%|█▋        | 11/63 [00:09<00:42,     299/299    0.5217    0.5691      1.19:  19%|█▉        | 12/63 [00:09<00:41,     299/299    0.5176    0.5656     1.185:  19%|█▉        | 12/63 [00:10<00:41,     299/299    0.5176    0.5656     1.185:  21%|██        | 13/63 [00:10<00:40,     299/299     0.513    0.5631     1.184:  21%|██        | 13/63 [00:11<00:40,     299/299     0.513    0.5631     1.184:  22%|██▏       | 14/63 [00:11<00:39,     299/299    0.5128    0.5599     1.175:  22%|██▏       | 14/63 [00:12<00:39,     299/299    0.5128    0.5599     1.175:  24%|██▍       | 15/63 [00:12<00:38,     299/299    0.5098    0.5609     1.183:  24%|██▍       | 15/63 [00:13<00:38,     299/299    0.5098    0.5609     1.183:  25%|██▌       | 16/63 [00:13<00:37,     299/299    0.5117    0.5617     1.178:  25%|██▌       | 16/63 [00:13<00:37,     299/299    0.5117    0.5617     1.178:  27%|██▋       | 17/63 [00:13<00:37,     299/299      0.51    0.5628      1.18:  27%|██▋       | 17/63 [00:14<00:37,     299/299      0.51    0.5628      1.18:  29%|██▊       | 18/63 [00:14<00:36,     299/299    0.5115    0.5591     1.183:  29%|██▊       | 18/63 [00:15<00:36,     299/299    0.5115    0.5591     1.183:  30%|███       | 19/63 [00:15<00:35,     299/299    0.5112    0.5595     1.179:  30%|███       | 19/63 [00:16<00:35,     299/299    0.5112    0.5595     1.179:  32%|███▏      | 20/63 [00:16<00:34,     299/299    0.5097    0.5626     1.185:  32%|███▏      | 20/63 [00:17<00:34,     299/299    0.5097    0.5626     1.185:  33%|███▎      | 21/63 [00:17<00:35,     299/299    0.5058    0.5601     1.182:  33%|███▎      | 21/63 [00:18<00:35,     299/299    0.5058    0.5601     1.182:  35%|███▍      | 22/63 [00:18<00:33,     299/299    0.5033    0.5603      1.18:  35%|███▍      | 22/63 [00:19<00:33,     299/299    0.5033    0.5603      1.18:  37%|███▋      | 23/63 [00:19<00:37,     299/299    0.5054    0.5607     1.181:  37%|███▋      | 23/63 [00:19<00:37,     299/299    0.5054    0.5607     1.181:  38%|███▊      | 24/63 [00:19<00:34,     299/299    0.5062     0.561     1.181:  38%|███▊      | 24/63 [00:20<00:34,     299/299    0.5062     0.561     1.181:  40%|███▉      | 25/63 [00:20<00:33,     299/299    0.5045    0.5591     1.177:  40%|███▉      | 25/63 [00:21<00:33,     299/299    0.5045    0.5591     1.177:  41%|████▏     | 26/63 [00:21<00:31,     299/299    0.5022    0.5577     1.175:  41%|████▏     | 26/63 [00:22<00:31,     299/299    0.5022    0.5577     1.175:  43%|████▎     | 27/63 [00:22<00:29,     299/299     0.503    0.5584     1.176:  43%|████▎     | 27/63 [00:23<00:29,     299/299     0.503    0.5584     1.176:  44%|████▍     | 28/63 [00:23<00:28,     299/299    0.5044      0.56     1.178:  44%|████▍     | 28/63 [00:24<00:28,     299/299    0.5044      0.56     1.178:  46%|████▌     | 29/63 [00:24<00:28,     299/299    0.5023    0.5594     1.176:  46%|████▌     | 29/63 [00:24<00:28,     299/299    0.5023    0.5594     1.176:  48%|████▊     | 30/63 [00:24<00:26,     299/299    0.5028      0.56     1.175:  48%|████▊     | 30/63 [00:25<00:26,     299/299    0.5028      0.56     1.175:  49%|████▉     | 31/63 [00:25<00:25,     299/299    0.5027    0.5608      1.18:  49%|████▉     | 31/63 [00:26<00:25,     299/299    0.5027    0.5608      1.18:  51%|█████     | 32/63 [00:26<00:24,     299/299    0.5058    0.5637     1.179:  51%|█████     | 32/63 [00:27<00:24,     299/299    0.5058    0.5637     1.179:  52%|█████▏    | 33/63 [00:27<00:24,     299/299    0.5072     0.566     1.183:  52%|█████▏    | 33/63 [00:27<00:24,     299/299    0.5072     0.566     1.183:  54%|█████▍    | 34/63 [00:27<00:23,     299/299     0.506    0.5652     1.183:  54%|█████▍    | 34/63 [00:28<00:23,     299/299     0.506    0.5652     1.183:  56%|█████▌    | 35/63 [00:28<00:22,     299/299    0.5045    0.5638     1.181:  56%|█████▌    | 35/63 [00:29<00:22,     299/299    0.5045    0.5638     1.181:  57%|█████▋    | 36/63 [00:29<00:21,     299/299    0.5051    0.5626     1.178:  57%|█████▋    | 36/63 [00:30<00:21,     299/299    0.5051    0.5626     1.178:  59%|█████▊    | 37/63 [00:30<00:20,     299/299     0.502    0.5619     1.179:  59%|█████▊    | 37/63 [00:31<00:20,     299/299     0.502    0.5619     1.179:  60%|██████    | 38/63 [00:31<00:19,     299/299     0.503    0.5631     1.181:  60%|██████    | 38/63 [00:31<00:19,     299/299     0.503    0.5631     1.181:  62%|██████▏   | 39/63 [00:31<00:18,     299/299    0.5029     0.562     1.181:  62%|██████▏   | 39/63 [00:32<00:18,     299/299    0.5029     0.562     1.181:  63%|██████▎   | 40/63 [00:32<00:18,     299/299    0.5042    0.5635     1.182:  63%|██████▎   | 40/63 [00:33<00:18,     299/299    0.5042    0.5635     1.182:  65%|██████▌   | 41/63 [00:33<00:17,     299/299    0.5042    0.5633     1.181:  65%|██████▌   | 41/63 [00:34<00:17,     299/299    0.5042    0.5633     1.181:  67%|██████▋   | 42/63 [00:34<00:16,     299/299    0.5031     0.562     1.181:  67%|██████▋   | 42/63 [00:35<00:16,     299/299    0.5031     0.562     1.181:  68%|██████▊   | 43/63 [00:35<00:16,     299/299    0.5025    0.5611     1.184:  68%|██████▊   | 43/63 [00:35<00:16,     299/299    0.5025    0.5611     1.184:  70%|██████▉   | 44/63 [00:35<00:15,     299/299    0.5031    0.5607     1.182:  70%|██████▉   | 44/63 [00:36<00:15,     299/299    0.5031    0.5607     1.182:  71%|███████▏  | 45/63 [00:36<00:14,     299/299    0.5045    0.5616     1.183:  71%|███████▏  | 45/63 [00:37<00:14,     299/299    0.5045    0.5616     1.183:  73%|███████▎  | 46/63 [00:37<00:13,     299/299    0.5056    0.5624     1.183:  73%|███████▎  | 46/63 [00:38<00:13,     299/299    0.5056    0.5624     1.183:  75%|███████▍  | 47/63 [00:38<00:12,     299/299    0.5053    0.5619     1.183:  75%|███████▍  | 47/63 [00:39<00:12,     299/299    0.5053    0.5619     1.183:  76%|███████▌  | 48/63 [00:39<00:11,     299/299    0.5064    0.5628     1.182:  76%|███████▌  | 48/63 [00:39<00:11,     299/299    0.5064    0.5628     1.182:  78%|███████▊  | 49/63 [00:39<00:11,     299/299    0.5064    0.5628     1.181:  78%|███████▊  | 49/63 [00:40<00:11,     299/299    0.5064    0.5628     1.181:  79%|███████▉  | 50/63 [00:40<00:10,     299/299    0.5061    0.5631      1.18:  79%|███████▉  | 50/63 [00:41<00:10,     299/299    0.5061    0.5631      1.18:  81%|████████  | 51/63 [00:41<00:09,     299/299    0.5055    0.5639      1.18:  81%|████████  | 51/63 [00:42<00:09,     299/299    0.5055    0.5639      1.18:  83%|████████▎ | 52/63 [00:42<00:08,     299/299    0.5054    0.5634     1.179:  83%|████████▎ | 52/63 [00:43<00:08,     299/299    0.5054    0.5634     1.179:  84%|████████▍ | 53/63 [00:43<00:08,     299/299    0.5061    0.5633      1.18:  84%|████████▍ | 53/63 [00:43<00:08,     299/299    0.5061    0.5633      1.18:  86%|████████▌ | 54/63 [00:43<00:07,     299/299    0.5063    0.5631      1.18:  86%|████████▌ | 54/63 [00:44<00:07,     299/299    0.5063    0.5631      1.18:  87%|████████▋ | 55/63 [00:44<00:06,     299/299    0.5062    0.5634     1.179:  87%|████████▋ | 55/63 [00:45<00:06,     299/299    0.5062    0.5634     1.179:  89%|████████▉ | 56/63 [00:45<00:05,     299/299    0.5058    0.5628     1.179:  89%|████████▉ | 56/63 [00:46<00:05,     299/299    0.5058    0.5628     1.179:  90%|█████████ | 57/63 [00:46<00:04,     299/299    0.5073    0.5635     1.179:  90%|█████████ | 57/63 [00:47<00:04,     299/299    0.5073    0.5635     1.179:  92%|█████████▏| 58/63 [00:47<00:04,     299/299     0.507    0.5632     1.179:  92%|█████████▏| 58/63 [00:47<00:04,     299/299     0.507    0.5632     1.179:  94%|█████████▎| 59/63 [00:47<00:03,     299/299    0.5076    0.5629     1.178:  94%|█████████▎| 59/63 [00:48<00:03,     299/299    0.5076    0.5629     1.178:  95%|█████████▌| 60/63 [00:48<00:02,     299/299    0.5087    0.5626     1.177:  95%|█████████▌| 60/63 [00:49<00:02,     299/299    0.5087    0.5626     1.177:  97%|█████████▋| 61/63 [00:49<00:01,     299/299    0.5087    0.5629     1.176:  97%|█████████▋| 61/63 [00:50<00:01,     299/299    0.5087    0.5629     1.176:  98%|█████████▊| 62/63 [00:50<00:00,     299/299    0.5069    0.5633     1.182:  98%|█████████▊| 62/63 [00:50<00:00,     299/299    0.5069    0.5633     1.182: 100%|██████████| 63/63 [00:50<00:00,     299/299    0.5069    0.5633     1.182: 100%|██████████| 63/63 [00:50<00:00,
38776.0s 42 
38776.0s 43 Training completed in 10.448 hours.
38783.8s 44 37642.86703205109
38789.9s 45 Collecting tqdm==4.64.0
38789.9s 46 Downloading tqdm-4.64.0-py2.py3-none-any.whl (78 kB)
38790.0s 47 [?25l     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/78.4 kB[0m [31m?[0m eta [36m-:--:--[0m[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m78.4/78.4 kB[0m [31m7.4 MB/s[0m eta [36m0:00:00[0m
38790.9s 48 [?25hInstalling collected packages: tqdm
38790.9s 49 Attempting uninstall: tqdm
38790.9s 50 Found existing installation: tqdm 4.65.0
38790.9s 51 Uninstalling tqdm-4.65.0:
38790.9s 52 Successfully uninstalled tqdm-4.65.0
38791.0s 53 [33m  WARNING: The script tqdm is installed in '/opt/conda/envs/newCondaEnvironment/bin' which is not on PATH.
38791.0s 54 Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.[0m[33m
38791.0s 55 [0mSuccessfully installed tqdm-4.64.0
38791.0s 56 [33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv[0m[33m
38791.2s 57 [0m/kaggle/working/YOLOv6
38795.9s 58 Namespace(data='data/coco.yaml', weights='/kaggle/working/YOLOv6/runs/train/exp/weights/best_ckpt.pt', batch_size=32, img_size=640, conf_thres=0.03, iou_thres=0.65, task='val', device='0', half=False, save_dir='runs/val/', name='exp', test_load_size=640, letterbox_return_int=False, scale_exact=False, force_no_pad=False, not_infer_on_rect=False, reproduce_640_eval=False, eval_config_file='./configs/experiment/eval_640_repro.py', do_coco_metric=True, do_pr_metric=True, plot_curve=True, plot_confusion_matrix=True, verbose=True, config_file='')
38795.9s 59 Loading checkpoint from /kaggle/working/YOLOv6/runs/train/exp/weights/best_ckpt.pt
38799.7s 60 
38799.7s 61 Fusing model...
38802.3s 62 /opt/conda/envs/newCondaEnvironment/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
38802.3s 63 return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
38802.6s 64 Switch model to deploy modality.
38802.8s 65 Model Summary: Params: 34.86M, Gflops: 85.79
38803.0s 66 Val: Checking formats of labels with 2 process(es):
38806.2s 67 0%|                                                  | 0/5000 [00:00<?, ?it/s]155 label(s) found, 0 label(s) missing, 0 label(s) empty, 0 invalid label files:321 label(s) found, 1 label(s) missing, 0 label(s) empty, 0 invalid label files:493 label(s) found, 4 label(s) missing, 0 label(s) empty, 0 invalid label files:669 label(s) found, 6 label(s) missing, 0 label(s) empty, 0 invalid label files:840 label(s) found, 7 label(s) missing, 0 label(s) empty, 0 invalid label files:986 label(s) found, 8 label(s) missing, 0 label(s) empty, 0 invalid label files:1123 label(s) found, 10 label(s) missing, 0 label(s) empty, 0 invalid label file1252 label(s) found, 10 label(s) missing, 0 label(s) empty, 0 invalid label file1373 label(s) found, 10 label(s) missing, 0 label(s) empty, 0 invalid label file1488 label(s) found, 10 label(s) missing, 0 label(s) empty, 0 invalid label file1597 label(s) found, 12 label(s) missing, 0 label(s) empty, 0 invalid label file1707 label(s) found, 12 label(s) missing, 0 label(s) empty, 0 invalid label file1815 label(s) found, 14 label(s) missing, 0 label(s) empty, 0 invalid label file1925 label(s) found, 14 label(s) missing, 0 label(s) empty, 0 invalid label file2032 label(s) found, 16 label(s) missing, 0 label(s) empty, 0 invalid label file2169 label(s) found, 17 label(s) missing, 0 label(s) empty, 0 invalid label file2340 label(s) found, 22 label(s) missing, 0 label(s) empty, 0 invalid label file2551 label(s) found, 23 label(s) missing, 0 label(s) empty, 0 invalid label file2783 label(s) found, 27 label(s) missing, 0 label(s) empty, 0 invalid label file3006 label(s) found, 29 label(s) missing, 0 label(s) empty, 0 invalid label file3199 label(s) found, 30 label(s) missing, 0 label(s) empty, 0 invalid label file3398 label(s) found, 32 label(s) missing, 0 label(s) empty, 0 invalid label file3592 label(s) found, 34 label(s) missing, 0 label(s) empty, 0 invalid label file3797 label(s) found, 34 label(s) missing, 0 label(s) empty, 0 invalid label file4036 label(s) found, 37 label(s) missing, 0 label(s) empty, 0 invalid label file4281 label(s) found, 40 label(s) missing, 0 label(s) empty, 0 invalid label file4528 label(s) found, 43 label(s) missing, 0 label(s) empty, 0 invalid label file4790 label(s) found, 48 label(s) missing, 0 label(s) empty, 0 invalid label file4952 label(s) found, 48 label(s) missing, 0 label(s) empty, 0 invalid label file
38806.6s 68 Val: Final numbers of valid images: 5000/ labels: 5000.
38806.6s 69 3.9s for dataset initialization.
39100.4s 70 Inferencing model in val datasets.:   0%|               | 0/157 [00:00<?, ?it/s]Inferencing model in val datasets.:   1%|       | 1/157 [00:02<06:46,  2.61s/it]Inferencing model in val datasets.:   1%|       | 2/157 [00:03<04:48,  1.86s/it]Inferencing model in val datasets.:   2%|▏      | 3/157 [00:05<04:50,  1.88s/it]Inferencing model in val datasets.:   3%|▏      | 4/157 [00:07<04:52,  1.91s/it]Inferencing model in val datasets.:   3%|▏      | 5/157 [00:09<04:36,  1.82s/it]Inferencing model in val datasets.:   4%|▎      | 6/157 [00:11<04:25,  1.76s/it]Inferencing model in val datasets.:   4%|▎      | 7/157 [00:12<04:28,  1.79s/it]Inferencing model in val datasets.:   5%|▎      | 8/157 [00:15<04:46,  1.92s/it]Inferencing model in val datasets.:   6%|▍      | 9/157 [00:17<04:43,  1.91s/it]Inferencing model in val datasets.:   6%|▍     | 10/157 [00:18<04:23,  1.79s/it]Inferencing model in val datasets.:   7%|▍     | 11/157 [00:20<04:38,  1.91s/it]Inferencing model in val datasets.:   8%|▍     | 12/157 [00:22<04:23,  1.82s/it]Inferencing model in val datasets.:   8%|▍     | 13/157 [00:23<04:13,  1.76s/it]Inferencing model in val datasets.:   9%|▌     | 14/157 [00:25<04:11,  1.76s/it]Inferencing model in val datasets.:  10%|▌     | 15/157 [00:27<04:14,  1.80s/it]Inferencing model in val datasets.:  10%|▌     | 16/157 [00:29<04:33,  1.94s/it]Inferencing model in val datasets.:  11%|▋     | 17/157 [00:31<04:18,  1.85s/it]Inferencing model in val datasets.:  11%|▋     | 18/157 [00:33<04:19,  1.87s/it]Inferencing model in val datasets.:  12%|▋     | 19/157 [00:35<04:16,  1.86s/it]Inferencing model in val datasets.:  13%|▊     | 20/157 [00:37<04:12,  1.84s/it]Inferencing model in val datasets.:  13%|▊     | 21/157 [00:38<04:12,  1.86s/it]Inferencing model in val datasets.:  14%|▊     | 22/157 [00:40<04:03,  1.80s/it]Inferencing model in val datasets.:  15%|▉     | 23/157 [00:42<03:51,  1.73s/it]Inferencing model in val datasets.:  15%|▉     | 24/157 [00:43<03:43,  1.68s/it]Inferencing model in val datasets.:  16%|▉     | 25/157 [00:45<03:47,  1.72s/it]Inferencing model in val datasets.:  17%|▉     | 26/157 [00:47<04:11,  1.92s/it]Inferencing model in val datasets.:  17%|█     | 27/157 [00:49<04:13,  1.95s/it]Inferencing model in val datasets.:  18%|█     | 28/157 [00:51<03:58,  1.85s/it]Inferencing model in val datasets.:  18%|█     | 29/157 [00:53<03:53,  1.82s/it]Inferencing model in val datasets.:  19%|█▏    | 30/157 [00:54<03:37,  1.71s/it]Inferencing model in val datasets.:  20%|█▏    | 31/157 [00:56<03:37,  1.73s/it]Inferencing model in val datasets.:  20%|█▏    | 32/157 [00:58<03:31,  1.69s/it]Inferencing model in val datasets.:  21%|█▎    | 33/157 [00:59<03:23,  1.64s/it]Inferencing model in val datasets.:  22%|█▎    | 34/157 [01:01<03:39,  1.78s/it]Inferencing model in val datasets.:  22%|█▎    | 35/157 [01:03<03:33,  1.75s/it]Inferencing model in val datasets.:  23%|█▍    | 36/157 [01:04<03:21,  1.66s/it]Inferencing model in val datasets.:  24%|█▍    | 37/157 [01:06<03:16,  1.64s/it]Inferencing model in val datasets.:  24%|█▍    | 38/157 [01:08<03:08,  1.59s/it]Inferencing model in val datasets.:  25%|█▍    | 39/157 [01:09<03:16,  1.66s/it]Inferencing model in val datasets.:  25%|█▌    | 40/157 [01:11<03:14,  1.66s/it]Inferencing model in val datasets.:  26%|█▌    | 41/157 [01:13<03:14,  1.67s/it]Inferencing model in val datasets.:  27%|█▌    | 42/157 [01:14<03:15,  1.70s/it]Inferencing model in val datasets.:  27%|█▋    | 43/157 [01:16<03:14,  1.70s/it]Inferencing model in val datasets.:  28%|█▋    | 44/157 [01:18<03:02,  1.62s/it]Inferencing model in val datasets.:  29%|█▋    | 45/157 [01:19<02:56,  1.58s/it]Inferencing model in val datasets.:  29%|█▊    | 46/157 [01:21<03:21,  1.81s/it]Inferencing model in val datasets.:  30%|█▊    | 47/157 [01:24<03:39,  1.99s/it]Inferencing model in val datasets.:  31%|█▊    | 48/157 [01:25<03:13,  1.77s/it]Inferencing model in val datasets.:  31%|█▊    | 49/157 [01:27<03:11,  1.77s/it]Inferencing model in val datasets.:  32%|█▉    | 50/157 [01:29<03:08,  1.76s/it]Inferencing model in val datasets.:  32%|█▉    | 51/157 [01:30<02:54,  1.65s/it]Inferencing model in val datasets.:  33%|█▉    | 52/157 [01:32<03:09,  1.80s/it]Inferencing model in val datasets.:  34%|██    | 53/157 [01:35<03:25,  1.98s/it]Inferencing model in val datasets.:  34%|██    | 54/157 [01:36<03:02,  1.77s/it]Inferencing model in val datasets.:  35%|██    | 55/157 [01:37<02:54,  1.71s/it]Inferencing model in val datasets.:  36%|██▏   | 56/157 [01:39<02:50,  1.69s/it]Inferencing model in val datasets.:  36%|██▏   | 57/157 [01:41<03:00,  1.81s/it]Inferencing model in val datasets.:  37%|██▏   | 58/157 [01:43<03:10,  1.93s/it]Inferencing model in val datasets.:  38%|██▎   | 59/157 [01:45<03:02,  1.87s/it]Inferencing model in val datasets.:  38%|██▎   | 60/157 [01:47<02:50,  1.76s/it]Inferencing model in val datasets.:  39%|██▎   | 61/157 [01:49<02:55,  1.83s/it]Inferencing model in val datasets.:  39%|██▎   | 62/157 [01:50<02:55,  1.85s/it]Inferencing model in val datasets.:  40%|██▍   | 63/157 [01:52<02:53,  1.84s/it]Inferencing model in val datasets.:  41%|██▍   | 64/157 [01:54<02:40,  1.73s/it]Inferencing model in val datasets.:  41%|██▍   | 65/157 [01:57<03:11,  2.08s/it]Inferencing model in val datasets.:  42%|██▌   | 66/157 [01:59<03:15,  2.15s/it]Inferencing model in val datasets.:  43%|██▌   | 67/157 [02:01<03:07,  2.09s/it]Inferencing model in val datasets.:  43%|██▌   | 68/157 [02:03<02:57,  1.99s/it]Inferencing model in val datasets.:  44%|██▋   | 69/157 [02:04<02:51,  1.95s/it]Inferencing model in val datasets.:  45%|██▋   | 70/157 [02:07<02:56,  2.03s/it]Inferencing model in val datasets.:  45%|██▋   | 71/157 [02:08<02:43,  1.90s/it]Inferencing model in val datasets.:  46%|██▊   | 72/157 [02:11<02:49,  2.00s/it]Inferencing model in val datasets.:  46%|██▊   | 73/157 [02:12<02:33,  1.83s/it]Inferencing model in val datasets.:  47%|██▊   | 74/157 [02:14<02:36,  1.88s/it]Inferencing model in val datasets.:  48%|██▊   | 75/157 [02:17<03:03,  2.24s/it]Inferencing model in val datasets.:  48%|██▉   | 76/157 [02:19<02:54,  2.15s/it]Inferencing model in val datasets.:  49%|██▉   | 77/157 [02:21<02:49,  2.12s/it]Inferencing model in val datasets.:  50%|██▉   | 78/157 [02:23<02:44,  2.08s/it]Inferencing model in val datasets.:  50%|███   | 79/157 [02:25<02:33,  1.97s/it]Inferencing model in val datasets.:  51%|███   | 80/157 [02:27<02:30,  1.96s/it]Inferencing model in val datasets.:  52%|███   | 81/157 [02:29<02:38,  2.09s/it]Inferencing model in val datasets.:  52%|███▏  | 82/157 [02:31<02:43,  2.19s/it]Inferencing model in val datasets.:  53%|███▏  | 83/157 [02:34<02:46,  2.26s/it]Inferencing model in val datasets.:  54%|███▏  | 84/157 [02:36<02:43,  2.24s/it]Inferencing model in val datasets.:  54%|███▏  | 85/157 [02:39<02:46,  2.31s/it]Inferencing model in val datasets.:  55%|███▎  | 86/157 [02:41<02:38,  2.23s/it]Inferencing model in val datasets.:  55%|███▎  | 87/157 [02:42<02:20,  2.00s/it]Inferencing model in val datasets.:  56%|███▎  | 88/157 [02:44<02:11,  1.90s/it]Inferencing model in val datasets.:  57%|███▍  | 89/157 [02:46<02:16,  2.00s/it]Inferencing model in val datasets.:  57%|███▍  | 90/157 [02:48<02:12,  1.98s/it]Inferencing model in val datasets.:  58%|███▍  | 91/157 [02:50<02:11,  1.99s/it]Inferencing model in val datasets.:  59%|███▌  | 92/157 [02:52<02:00,  1.85s/it]Inferencing model in val datasets.:  59%|███▌  | 93/157 [02:54<02:03,  1.93s/it]Inferencing model in val datasets.:  60%|███▌  | 94/157 [02:55<01:59,  1.89s/it]Inferencing model in val datasets.:  61%|███▋  | 95/157 [02:57<02:00,  1.94s/it]Inferencing model in val datasets.:  61%|███▋  | 96/157 [03:00<02:02,  2.01s/it]Inferencing model in val datasets.:  62%|███▋  | 97/157 [03:02<02:07,  2.13s/it]Inferencing model in val datasets.:  62%|███▋  | 98/157 [03:04<01:59,  2.02s/it]Inferencing model in val datasets.:  63%|███▊  | 99/157 [03:06<02:02,  2.12s/it]Inferencing model in val datasets.:  64%|███▏ | 100/157 [03:09<02:08,  2.25s/it]Inferencing model in val datasets.:  64%|███▏ | 101/157 [03:11<02:02,  2.19s/it]Inferencing model in val datasets.:  65%|███▏ | 102/157 [03:13<02:00,  2.19s/it]Inferencing model in val datasets.:  66%|███▎ | 103/157 [03:15<01:57,  2.17s/it]Inferencing model in val datasets.:  66%|███▎ | 104/157 [03:17<01:52,  2.13s/it]Inferencing model in val datasets.:  67%|███▎ | 105/157 [03:19<01:47,  2.07s/it]Inferencing model in val datasets.:  68%|███▍ | 106/157 [03:21<01:41,  1.99s/it]Inferencing model in val datasets.:  68%|███▍ | 107/157 [03:23<01:35,  1.91s/it]Inferencing model in val datasets.:  69%|███▍ | 108/157 [03:24<01:31,  1.87s/it]Inferencing model in val datasets.:  69%|███▍ | 109/157 [03:26<01:30,  1.89s/it]Inferencing model in val datasets.:  70%|███▌ | 110/157 [03:28<01:27,  1.86s/it]Inferencing model in val datasets.:  71%|███▌ | 111/157 [03:30<01:27,  1.89s/it]Inferencing model in val datasets.:  71%|███▌ | 112/157 [03:32<01:30,  2.00s/it]Inferencing model in val datasets.:  72%|███▌ | 113/157 [03:34<01:26,  1.98s/it]Inferencing model in val datasets.:  73%|███▋ | 114/157 [03:36<01:21,  1.90s/it]Inferencing model in val datasets.:  73%|███▋ | 115/157 [03:38<01:17,  1.84s/it]Inferencing model in val datasets.:  74%|███▋ | 116/157 [03:40<01:21,  1.98s/it]Inferencing model in val datasets.:  75%|███▋ | 117/157 [03:43<01:33,  2.33s/it]Inferencing model in val datasets.:  75%|███▊ | 118/157 [03:45<01:31,  2.34s/it]Inferencing model in val datasets.:  76%|███▊ | 119/157 [03:47<01:22,  2.17s/it]Inferencing model in val datasets.:  76%|███▊ | 120/157 [03:49<01:17,  2.09s/it]Inferencing model in val datasets.:  77%|███▊ | 121/157 [03:51<01:09,  1.93s/it]Inferencing model in val datasets.:  78%|███▉ | 122/157 [03:52<01:04,  1.84s/it]Inferencing model in val datasets.:  78%|███▉ | 123/157 [03:54<01:02,  1.83s/it]Inferencing model in val datasets.:  79%|███▉ | 124/157 [03:56<01:02,  1.89s/it]Inferencing model in val datasets.:  80%|███▉ | 125/157 [03:59<01:08,  2.15s/it]Inferencing model in val datasets.:  80%|████ | 126/157 [04:01<01:01,  2.00s/it]Inferencing model in val datasets.:  81%|████ | 127/157 [04:02<00:56,  1.90s/it]Inferencing model in val datasets.:  82%|████ | 128/157 [04:04<00:55,  1.90s/it]Inferencing model in val datasets.:  82%|████ | 129/157 [04:06<00:50,  1.82s/it]Inferencing model in val datasets.:  83%|████▏| 130/157 [04:08<00:48,  1.81s/it]Inferencing model in val datasets.:  83%|████▏| 131/157 [04:09<00:44,  1.69s/it]Inferencing model in val datasets.:  84%|████▏| 132/157 [04:11<00:42,  1.71s/it]Inferencing model in val datasets.:  85%|████▏| 133/157 [04:12<00:41,  1.72s/it]Inferencing model in val datasets.:  85%|████▎| 134/157 [04:14<00:39,  1.73s/it]Inferencing model in val datasets.:  86%|████▎| 135/157 [04:17<00:45,  2.05s/it]Inferencing model in val datasets.:  87%|████▎| 136/157 [04:19<00:42,  2.04s/it]Inferencing model in val datasets.:  87%|████▎| 137/157 [04:21<00:41,  2.06s/it]Inferencing model in val datasets.:  88%|████▍| 138/157 [04:23<00:37,  1.99s/it]Inferencing model in val datasets.:  89%|████▍| 139/157 [04:24<00:33,  1.84s/it]Inferencing model in val datasets.:  89%|████▍| 140/157 [04:26<00:29,  1.75s/it]Inferencing model in val datasets.:  90%|████▍| 141/157 [04:27<00:25,  1.62s/it]Inferencing model in val datasets.:  90%|████▌| 142/157 [04:29<00:25,  1.67s/it]Inferencing model in val datasets.:  91%|████▌| 143/157 [04:31<00:23,  1.70s/it]Inferencing model in val datasets.:  92%|████▌| 144/157 [04:33<00:22,  1.71s/it]Inferencing model in val datasets.:  92%|████▌| 145/157 [04:34<00:21,  1.75s/it]Inferencing model in val datasets.:  93%|████▋| 146/157 [04:36<00:19,  1.80s/it]Inferencing model in val datasets.:  94%|████▋| 147/157 [04:38<00:17,  1.74s/it]Inferencing model in val datasets.:  94%|████▋| 148/157 [04:40<00:15,  1.77s/it]Inferencing model in val datasets.:  95%|████▋| 149/157 [04:41<00:13,  1.73s/it]Inferencing model in val datasets.:  96%|████▊| 150/157 [04:43<00:12,  1.74s/it]Inferencing model in val datasets.:  96%|████▊| 151/157 [04:45<00:09,  1.64s/it]Inferencing model in val datasets.:  97%|████▊| 152/157 [04:46<00:08,  1.67s/it]Inferencing model in val datasets.:  97%|████▊| 153/157 [04:48<00:06,  1.54s/it]Inferencing model in val datasets.:  98%|████▉| 154/157 [04:49<00:04,  1.46s/it]Inferencing model in val datasets.:  99%|████▉| 155/157 [04:51<00:03,  1.70s/it]Inferencing model in val datasets.:  99%|████▉| 156/157 [04:53<00:01,  1.68s/it]Inferencing model in val datasets.: 100%|█████| 157/157 [04:53<00:00,  1.30s/it]Inferencing model in val datasets.: 100%|█████| 157/157 [04:53<00:00,  1.87s/it]
39105.1s 71 IOU 50 best mF1 thershold near 0.317.
39105.1s 72 Class                 Images      Labels     P@.5iou     R@.5iou    F1@.5iou      mAP@.5  mAP@.5:.95
39105.1s 73 all                     5000       36335       0.161       0.134       0.123      0.0822      0.0458
39105.1s 74 person                  5000       10777        0.43        0.51       0.467       0.462       0.235
39105.1s 75 bicycle                 5000         314       0.193      0.0573      0.0884      0.0398      0.0195
39105.1s 76 car                     5000        1918        0.34       0.237       0.279       0.199      0.0997
39105.1s 77 motorcycle              5000         367       0.309       0.226       0.261       0.173      0.0746
39105.1s 78 airplane                5000         143       0.134       0.407       0.202       0.249       0.106
39105.1s 79 bus                     5000         283       0.221        0.36       0.274       0.226       0.154
39105.1s 80 train                   5000         190       0.193        0.33       0.243       0.158       0.084
39105.1s 81 truck                   5000         414       0.157       0.176       0.166      0.0708      0.0375
39105.1s 82 boat                    5000         424       0.104       0.033      0.0502      0.0204     0.00728
39105.1s 83 traffic light           5000         634       0.186      0.0662      0.0977      0.0389      0.0169
39105.1s 84 fire hydrant            5000         101           0           0           0     0.00702      0.0036
39105.1s 85 stop sign               5000          75       0.358        0.44       0.395       0.374       0.297
39105.1s 86 parking meter           5000          60           0           0           0     0.00421     0.00188
39105.1s 87 bench                   5000         411      0.0749      0.0146      0.0244       0.012     0.00422
39105.1s 88 bird                    5000         427      0.0618      0.0679      0.0647      0.0166     0.00858
39105.1s 89 cat                     5000         202        0.21       0.273       0.238       0.135      0.0656
39105.1s 90 dog                     5000         218       0.147      0.0917       0.113      0.0627      0.0367
39105.1s 91 horse                   5000         272       0.142       0.357       0.203       0.157      0.0671
39105.1s 92 sheep                   5000         354       0.194       0.223       0.208       0.109      0.0549
39105.1s 93 cow                     5000         372       0.254       0.195       0.221       0.134      0.0799
39105.1s 94 elephant                5000         252       0.173       0.429       0.247       0.261       0.169
39105.1s 95 bear                    5000          71       0.214       0.577       0.313       0.293       0.203
39105.1s 96 zebra                   5000         266       0.373       0.462       0.413       0.416       0.224
39105.1s 97 giraffe                 5000         232       0.371       0.444       0.404       0.412       0.223
39105.1s 98 backpack                5000         371           0           0           0     0.00282    0.000986
39105.1s 99 umbrella                5000         407       0.124       0.118       0.121      0.0491      0.0199
39105.1s 100 handbag                 5000         540      0.0905      0.0037     0.00712     0.00278      0.0013
39105.1s 101 tie                     5000         252      0.0421      0.0119      0.0186     0.00286    0.000783
39105.1s 102 suitcase                5000         299      0.0192     0.00669     0.00993     0.00222    0.000749
39105.1s 103 frisbee                 5000         115       0.103      0.0348       0.052      0.0135      0.0087
39105.1s 104 skis                    5000         241       0.112      0.0705      0.0866      0.0374      0.0151
39105.1s 105 snowboard               5000          69       0.082      0.0145      0.0246      0.0115     0.00358
39105.1s 106 sports ball             5000         260       0.247       0.165       0.198       0.118      0.0791
39105.1s 107 kite                    5000         327       0.186       0.272       0.221       0.108      0.0499
39105.1s 108 baseball bat            5000         145           0           0           0     0.00158    0.000427
39105.1s 109 baseball glove          5000         148      0.0457       0.027       0.034     0.00716     0.00345
39105.1s 110 skateboard              5000         179       0.171       0.101       0.127      0.0519      0.0203
39105.1s 111 surfboard               5000         267           0           0           0     0.00397     0.00125
39105.1s 112 tennis racket           5000         225        0.05     0.00889      0.0151     0.00844     0.00315
39105.1s 113 bottle                  5000        1013       0.201      0.0494      0.0792      0.0404      0.0176
39105.1s 114 wine glass              5000         341      0.0892      0.0147      0.0252      0.0103     0.00566
39105.1s 115 cup                     5000         895       0.218       0.139       0.169      0.0804      0.0476
39105.1s 116 fork                    5000         215           0           0           0    0.000577    0.000123
39105.1s 117 knife                   5000         325           0           0           0     0.00062    0.000282
39105.1s 118 spoon                   5000         253           0           0           0    0.000818    0.000282
39105.1s 119 bowl                    5000         623       0.176        0.21       0.191       0.102      0.0625
39105.1s 120 banana                  5000         370       0.097      0.0514      0.0672      0.0167     0.00705
39105.1s 121 apple                   5000         236      0.0553      0.0593      0.0573      0.0115     0.00817
39105.1s 122 sandwich                5000         177       0.122       0.147       0.134      0.0675      0.0374
39105.1s 123 orange                  5000         285       0.192       0.184       0.188      0.0972       0.063
39105.1s 124 broccoli                5000         312        0.17       0.115       0.137      0.0664       0.024
39105.1s 125 carrot                  5000         365      0.0689      0.0493      0.0575      0.0155     0.00629
39105.1s 126 hot dog                 5000         125      0.0662       0.056      0.0607       0.015     0.00514
39105.1s 127 pizza                   5000         284       0.301       0.363       0.329       0.248       0.143
39105.1s 128 donut                   5000         328        0.11       0.149       0.127      0.0617      0.0445
39105.1s 129 cake                    5000         310      0.0832         0.1      0.0908      0.0358      0.0178
39105.1s 130 chair                   5000        1771       0.167      0.0519      0.0793      0.0324      0.0147
39105.1s 131 couch                   5000         261       0.155       0.069      0.0954      0.0509      0.0276
39105.1s 132 potted plant            5000         342       0.111      0.0468      0.0658      0.0164     0.00689
39105.1s 133 bed                     5000         163        0.16       0.123       0.139      0.0759      0.0358
39105.1s 134 dining table            5000         695       0.231       0.268       0.248       0.151      0.0805
39105.1s 135 toilet                  5000         179       0.198       0.397       0.265       0.237       0.155
39105.1s 136 tv                      5000         288       0.202       0.236       0.218       0.146      0.0892
39105.1s 137 laptop                  5000         231       0.223       0.134       0.168      0.0874      0.0464
39105.1s 138 mouse                   5000         106       0.144      0.0189      0.0334      0.0255      0.0168
39105.1s 139 remote                  5000         283      0.0509     0.00707      0.0124     0.00217     0.00143
39105.1s 140 keyboard                5000         153       0.236        0.17       0.198       0.104       0.044
39105.1s 141 cell phone              5000         262       0.124      0.0115       0.021      0.0101     0.00592
39105.1s 142 microwave               5000          55       0.103       0.145       0.121      0.0358      0.0213
39105.1s 143 oven                    5000         143       0.112      0.0559      0.0746      0.0331      0.0161
39105.1s 144 toaster                 5000           9           1           0           0    0.000937    0.000562
39105.1s 145 sink                    5000         225       0.111      0.0444      0.0636      0.0211      0.0128
39105.1s 146 refrigerator            5000         126      0.0924       0.103      0.0975      0.0301      0.0172
39105.1s 147 book                    5000        1129      0.0802      0.0301      0.0438      0.0115     0.00317
39105.1s 148 clock                   5000         267       0.132       0.262       0.175       0.149       0.081
39105.1s 149 vase                    5000         274       0.126      0.0292      0.0474      0.0137     0.00763
39105.1s 150 scissors                5000          36           1           0           0     3.2e-05    2.88e-05
39105.1s 151 teddy bear              5000         190      0.0716      0.0421       0.053      0.0211      0.0093
39105.1s 152 hair drier              5000          11           0           0           0           0           0
39105.1s 153 toothbrush              5000          57           0           0           0           0           0
39105.1s 154 WARNING: ConfusionMatrix plot failure: No module named 'seaborn'
39105.1s 155 
39105.1s 156 Evaluating speed.
39105.1s 157 Average pre-process time: 0.12 ms
39105.1s 158 Average inference time: 7.96 ms
39105.1s 159 Average NMS time: 28.16 ms
39105.1s 160 
39105.1s 161 Evaluating mAP by pycocotools.
39105.1s 162 Saving runs/val/exp/predictions.json...
39125.0s 163 loading annotations into memory...
39125.4s 164 Done (t=0.42s)
39125.4s 165 creating index...
39125.4s 166 index created!
39125.4s 167 Loading and preparing results...
39137.2s 168 DONE (t=9.05s)
39137.2s 169 creating index...
39137.2s 170 index created!
39137.2s 171 Running per image evaluation...
39137.2s 172 Evaluate annotation type *bbox*
39228.0s 173 DONE (t=89.10s).
39228.0s 174 Accumulating evaluation results...
39263.5s 175 DONE (t=35.56s).
39263.5s 176 Class           Labeled_images      Labels     P@.5iou     R@.5iou    F1@.5iou      mAP@.5  mAP@.5:.95
39263.5s 177 all                     4952       36335       0.159         0.2       0.177      0.0851      0.0481
39263.5s 178 person                  2693       10777       0.603        0.46       0.522       0.491       0.252
39263.5s 179 bicycle                  149         314       0.103        0.14       0.119      0.0443      0.0233
39263.5s 180 car                      535        1918       0.439        0.21       0.284       0.204       0.104
39263.5s 181 motorcycle               159         367       0.352        0.22       0.271       0.178      0.0779
39263.5s 182 airplane                  97         143        0.47        0.27       0.343       0.251       0.108
39263.5s 183 bus                      189         283       0.321         0.3        0.31       0.228       0.157
39263.5s 184 train                    157         190       0.314        0.22       0.259       0.161       0.087
39263.5s 185 truck                    250         414       0.158        0.17       0.164      0.0745      0.0411
39263.5s 186 boat                     121         424      0.0704        0.09       0.079      0.0228     0.00947
39263.5s 187 traffic light            191         634       0.115         0.1       0.107      0.0435      0.0209
39263.5s 188 fire hydrant              86         101      0.0292        0.04      0.0338     0.00704     0.00364
39263.5s 189 stop sign                 69          75       0.583        0.37       0.453       0.378       0.302
39263.5s 190 parking meter             37          60      0.0375        0.05      0.0429     0.00454       0.002
39263.5s 191 bench                    235         411      0.0691        0.06      0.0642      0.0125     0.00452
39263.5s 192 bird                     125         427      0.0539         0.1        0.07      0.0184     0.00994
39263.5s 193 cat                      184         202       0.224        0.26        0.24       0.137      0.0674
39263.5s 194 dog                      177         218       0.112        0.16       0.132      0.0648      0.0387
39263.5s 195 horse                    128         272       0.203        0.28       0.235       0.161      0.0703
39263.5s 196 sheep                     65         354       0.215        0.21       0.213       0.113      0.0587
39263.5s 197 cow                       87         372       0.234        0.22       0.227       0.144      0.0872
39263.5s 198 elephant                  89         252       0.616        0.21       0.313       0.268       0.174
39263.5s 199 bear                      49          71       0.301        0.43       0.354       0.295       0.205
39263.5s 200 zebra                     85         266       0.671        0.38       0.485       0.426        0.23
39263.5s 201 giraffe                  101         232       0.656        0.35       0.456       0.413       0.226
39263.5s 202 backpack                 228         371      0.0213        0.03      0.0249     0.00297     0.00107
39263.5s 203 umbrella                 174         407       0.136        0.11       0.122      0.0535      0.0218
39263.5s 204 handbag                  292         540      0.0214        0.02      0.0207     0.00398      0.0019
39263.5s 205 tie                      145         252       0.031        0.03      0.0305     0.00305    0.000869
39263.5s 206 suitcase                 105         299      0.0274        0.02      0.0231     0.00243    0.000887
39263.5s 207 frisbee                   84         115      0.0769        0.04      0.0526      0.0144     0.00944
39263.5s 208 skis                     120         241       0.113        0.07      0.0863      0.0409       0.017
39263.5s 209 snowboard                 49          69      0.0638        0.04      0.0492      0.0138     0.00431
39263.5s 210 sports ball              169         260       0.261        0.16       0.198       0.123      0.0838
39263.5s 211 kite                      91         327       0.327         0.2       0.248       0.119      0.0562
39263.5s 212 baseball bat              97         145      0.0113        0.08      0.0198      0.0016    0.000441
39263.5s 213 baseball glove           100         148      0.0331        0.08      0.0469      0.0079     0.00395
39263.5s 214 skateboard               127         179       0.155        0.12       0.135      0.0563      0.0233
39263.5s 215 surfboard                149         267      0.0161        0.06      0.0254     0.00398     0.00128
39263.5s 216 tennis racket            167         225       0.037        0.08      0.0506     0.00886     0.00335
39263.5s 217 bottle                   379        1013      0.0962        0.15       0.117      0.0449      0.0206
39263.5s 218 wine glass               110         341      0.0418        0.04      0.0409      0.0151     0.00955
39263.5s 219 cup                      390         895       0.208        0.16       0.181      0.0839      0.0507
39263.5s 220 fork                     155         215     0.00694        0.03      0.0113    0.000622    0.000148
39263.5s 221 knife                    181         325     0.00997        0.02      0.0133    0.000788    0.000364
39263.5s 222 spoon                    153         253      0.0115        0.02      0.0146    0.000953     0.00035
39263.5s 223 bowl                     314         623        0.19         0.2       0.195       0.106      0.0672
39263.5s 224 banana                   103         370       0.092        0.08      0.0856      0.0191     0.00882
39263.5s 225 apple                     76         236       0.066        0.08      0.0723       0.012     0.00863
39263.5s 226 sandwich                  98         177       0.124        0.17       0.144      0.0717       0.041
39263.5s 227 orange                    85         285       0.239        0.17       0.199       0.101      0.0674
39263.5s 228 broccoli                  71         312       0.143        0.15       0.147      0.0726      0.0277
39263.5s 229 carrot                    81         365      0.0548        0.11      0.0732      0.0174     0.00706
39263.5s 230 hot dog                   51         125      0.0635        0.06      0.0617      0.0161     0.00568
39263.5s 231 pizza                    153         284       0.367        0.32       0.342       0.251       0.146
39263.5s 232 donut                     62         328       0.137        0.13       0.133      0.0662      0.0491
39263.5s 233 cake                     124         310      0.0686        0.19       0.101      0.0407      0.0214
39263.5s 234 chair                    580        1771      0.0933         0.1      0.0965      0.0352       0.017
39263.5s 235 couch                    195         261      0.0917        0.19       0.124      0.0522       0.029
39263.5s 236 potted plant             172         342      0.0616        0.09      0.0732       0.017      0.0073
39263.5s 237 bed                      149         163       0.207        0.11       0.144        0.08      0.0377
39263.5s 238 dining table             501         695       0.311        0.23       0.265       0.155      0.0836
39263.5s 239 toilet                   149         179       0.413        0.25       0.311       0.239       0.158
39263.5s 240 tv                       207         288       0.227        0.23       0.229       0.149      0.0929
39263.5s 241 laptop                   183         231       0.185        0.19       0.187      0.0914      0.0504
39263.5s 242 mouse                     88         106      0.0926        0.09      0.0913      0.0269      0.0178
39263.5s 243 remote                   145         283      0.0732        0.01      0.0176     0.00273     0.00186
39263.5s 244 keyboard                 106         153        0.23        0.18       0.202       0.105      0.0453
39263.5s 245 cell phone               214         262      0.0774        0.04      0.0527      0.0109     0.00661
39263.5s 246 microwave                 54          55       0.114        0.18       0.139      0.0367      0.0221
39263.5s 247 oven                     115         143       0.121        0.08      0.0964      0.0352      0.0182
39263.5s 248 toaster                    8           9     0.00813        0.11      0.0151    0.000966     0.00058
39263.5s 249 sink                     187         225         0.1        0.08      0.0889      0.0221      0.0136
39263.5s 250 refrigerator             101         126      0.0947        0.14       0.113      0.0309      0.0181
39263.5s 251 book                     230        1129      0.0789        0.07      0.0742      0.0147     0.00407
39263.5s 252 clock                    204         267       0.306        0.18       0.227       0.152      0.0846
39263.5s 253 vase                     137         274      0.0552        0.09      0.0684      0.0144     0.00813
39263.5s 254 scissors                  28          36     0.00121        0.02     0.00228    3.59e-05    3.23e-05
39263.5s 255 teddy bear                94         190      0.0785         0.1       0.088      0.0217     0.00972
39263.5s 256 hair drier                 9          11           0           0           0           0           0
39263.5s 257 toothbrush                34          57           0           0           0           0           0
39263.5s 258 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.048
39263.5s 259 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.085
39263.5s 260 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.048
39263.5s 261 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.022
39263.5s 262 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.050
39263.5s 263 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.068
39263.5s 264 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.117
39263.5s 265 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.239
39263.5s 266 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.261
39263.5s 267 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.106
39263.5s 268 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.281
39263.5s 269 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.370
39263.5s 270 Results saved to runs/val/exp
39276.4s 271 /opt/conda/envs/newCondaEnvironment/lib/python3.10/site-packages/traitlets/traitlets.py:2930: FutureWarning: --Exporter.preprocessors=["remove_papermill_header.RemovePapermillHeader"] for containers is deprecated in traitlets 5.0. You can pass `--Exporter.preprocessors item` ... multiple times to add items to a list.
39276.4s 272 warn(
39276.4s 273 [NbConvertApp] Converting notebook __notebook__.ipynb to notebook
39292.3s 274 [NbConvertApp] Writing 326298 bytes to __notebook__.ipynb
39293.3s 275 /opt/conda/envs/newCondaEnvironment/lib/python3.10/site-packages/traitlets/traitlets.py:2930: FutureWarning: --Exporter.preprocessors=["nbconvert.preprocessors.ExtractOutputPreprocessor"] for containers is deprecated in traitlets 5.0. You can pass `--Exporter.preprocessors item` ... multiple times to add items to a list.
39293.3s 276 warn(
39293.3s 277 [NbConvertApp] Converting notebook __notebook__.ipynb to html
39294.4s 278 [NbConvertApp] Writing 569586 bytes to __results__.html